- byte pair encoding
- training neural networks (section B.4, appendix A)
- one-hot encoding (embedding layer - one-hot encoding + matrix multiplication in a fully connected layer, 
    https://github.com/rasbt/LLMs-from-scratch/tree/main/ch02/03_bonus_embedding-vs-matmul)
- In our variance calculation method, we use an implementation detail by setting
    unbiased=False. For those curious about what this means, in the variance calcula-
    tion, we divide by the number of inputs n in the variance formula. This approach does
    not apply Bessel’s correction, which typically uses n – 1 instead of n in the denomi-
    nator to adjust for bias in sample variance estimation. This decision results in a so-
    called biased estimate of the variance.
